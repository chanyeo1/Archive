{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHTohth7tdq"
      },
      "outputs": [],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuK7J1DF7zFv",
        "outputId": "d26c89cd-28b8-4796-d1df-d21edfdefe09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0kkzSvM776v",
        "outputId": "beeb5f54-7358-490e-b9f7-1f1c96b8d4fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDEk_gZP8Iiw",
        "outputId": "b77487ad-026b-4e4a-8568-e75ecbc46d76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-007ef8c9-b518-4cec-8eaf-fa627ac86fc4-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke([HumanMessage(content=\"What's my name?\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxOf6ZnT8RSt",
        "outputId": "ee40d3be-6f46-4461-d18f-045914f6dcb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm sorry, I do not know your name as I am an AI assistant and do not have access to personal information.\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 12, 'total_tokens': 37}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bba7573b-570b-4115-8e05-1922b99462fb-0', usage_metadata={'input_tokens': 12, 'output_tokens': 25, 'total_tokens': 37})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
        "        AIMessage(content=\"Hello Bob! How can i assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiegdBuC8f3f",
        "outputId": "394eaa35-88e3-4ea6-eda3-6c09b67a8bd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Your name is Bob.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 35, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fc4b1f0d-9618-49a6-bf36-89bb65d41f0b-0', usage_metadata={'input_tokens': 35, 'output_tokens': 5, 'total_tokens': 40})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Message History"
      ],
      "metadata": {
        "id": "HhQW80zq81pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "knDPK69Q8zC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "# session_id 문자열을 받아서 BaseChatMessageHistory를 반환하는 함수\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "  if session_id not in store:\n",
        "    store[session_id] = ChatMessageHistory()\n",
        "  return store[session_id]\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(model, get_session_history) # 메세지 히스토리를 사용하는 모델\n",
        "\n",
        "# refer\n",
        "# https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.chat_message_histories\n",
        "# https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#langchain_core.runnables.history.RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "grDkBMO986Ne"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "o6lQkwKJ99HO",
        "outputId": "235d30a6-6dad-4f69-faee-affaa985f593"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 47bc7fb4-bded-4ef1-9848-d3d57bc28e1d not found for run 217c11d6-4e1a-43c9-a3c8-2450dc6a491a. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qK848aj0-wnJ",
        "outputId": "f0cdb54b-3095-4658-d29f-27b4394abfbd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run dff35a74-871e-4b79-ac3c-f0473bfab249 not found for run b4c9d3e4-2025-4c4a-a450-d5ff9b94c789. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob. How can I help you today, Bob?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다른 세션 사용하기\n",
        "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qiQBsxSC_EgG",
        "outputId": "5a9c980c-ea88-4218-a47e-0221f396ed1c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 14416028-ffe1-4b1e-99be-862ed62205e6 not found for run 45869beb-5943-4459-84e1-4ba2ce5ad987. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I do not know your name as we are communicating through text on a digital platform.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래 세션으로 돌아오기\n",
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What's my name?\")\n",
        "    ],\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "n9JLpR4b_TKH",
        "outputId": "c5f350ba-39c5-4e15-c702-a01e9309576e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run fef36e6a-c1ed-436c-b44d-f550b890fd39 not found for run e3ffec8e-f025-46dd-a6c1-7b77b1cd1e0e. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob. How can I assist you today, Bob?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates"
      ],
      "metadata": {
        "id": "uuKXlmjO_mVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),  # messages 변수 값을 사용\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "RsXLKXJg_jiP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm bob\")] # messages 변수 값을 정의\n",
        "    }\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KrM--EYPANge",
        "outputId": "db63d9a5-a9d1-470b-a5b6-5cf112d0fb99"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history) # model\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc5\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Jim.\")],\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "5KijSzz4AsXv",
        "outputId": "39294b77-f170-495e-e1e7-4dd4c9eddc9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 99cd1638-3916-427c-a128-66c561001b83 not found for run 1344b162-417a-4d8c-b2f5-973fff6bac1e. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Jim! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시 물어보기\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Jgne-15mA8lv",
        "outputId": "7ee624d0-850d-4e31-bf3b-edff7eeb61d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 26b694ca-d91d-4c7f-8c8c-bbd7b4f5c7cc not found for run 5acee527-a6d2-4c34-97d5-1cbad3aa6e43. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Jim.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}\"),  # language 변수 값을 사용\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),  # messages 변수 값을 사용\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "Bhaoj1F-BGju"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm bob\")],  # messages 변수 값을 정의\n",
        "        \"language\": \"Spanish\",  # language 변수 값을 정의\n",
        "    }\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jPhdZ0goBkke",
        "outputId": "3b3b73a6-3947-49bf-8f34-dda410448b98"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¡Hola, Bob! ¿En qué puedo ayudarte hoy?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,                          # 기존 model 대신에 chain을 사용\n",
        "    get_session_history,            # 메세지 히스토리\n",
        "    input_messages_key=\"messages\",  # MessagePlaceholder에서 사용하는 변수명 지정\n",
        ")"
      ],
      "metadata": {
        "id": "VlXp0zVLCbR9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc11\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm todd\")],\n",
        "        \"language\": \"Spanish\",\n",
        "    },  # with_message_history의 첫번째 인수는 chain에 입력된다.\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "EvzDB4UuCpL2",
        "outputId": "56d922b3-ae4e-495f-b317-9e3e89b823fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 7ae21c26-4bf9-4f26-837b-5b8ddf78bfcb not found for run 53de1135-5d3b-4251-8574-7e582c4957e8. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¡Hola Todd! ¿En qué puedo ayudarte hoy?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"Spanish\",\n",
        "    },\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mlJjb3SVD8MW",
        "outputId": "460e6858-9df0-4505-c2c8-db3c68be300e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 9ef9940c-ad18-40ef-a2ee-a0c952704a69 not found for run 44411cbd-fe7b-4977-8a67-3db31ec03ca3. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tu nombre es Todd. ¿Hay algo más en lo que pueda ayudarte?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing Conversation History\n",
        "\n",
        "- 챗봇을 만들때 이해해야할 중요한 개념은 대화 히스토리 관리 방법이다.\n",
        "- 대화 히스토리를 관리하지 않으면 메세지 리스트는 제한없이 늘어나게 되고 잠재적으로 LLM의 컨텍스트 윈도우를 오버플로우할 가능성이 있다.\n",
        "- 그러므로, 전달하는 메세지의 크기를 제한하는 단계를 추가하는 것이 중요하다."
      ],
      "metadata": {
        "id": "h-YVE5XQEMFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=65,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"you're a good assistant\"),\n",
        "    HumanMessage(content=\"hi! I'm bob\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQe5B7nHEJq2",
        "outputId": "9a9009ed-faf3-4fc8-f5dc-3c17ee5408c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content=\"you're a good assistant\"),\n",
              " HumanMessage(content='whats 2 + 2'),\n",
              " AIMessage(content='4'),\n",
              " HumanMessage(content='thanks'),\n",
              " AIMessage(content='no problem!'),\n",
              " HumanMessage(content='having fun?'),\n",
              " AIMessage(content='yes!')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) # prompt에 입력하기 전에 trimmer에게 전달\n",
        "    | prompt\n",
        "    | model\n",
        ")\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lkJfeSzsEmYW",
        "outputId": "a039b6a3-4585-415f-a502-14dac2d31ead"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I don't have access to personal information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aYXnQ795Hb_s",
        "outputId": "0f1c976e-4466-4705-8b28-0558347c8512"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You asked what is 2 + 2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,  # 메세지를 입력하고 AI로부터 출력값을 생성하는 체인을 지정 (trimmer 추가)\n",
        "    get_session_history,  # 메세지 목록과, config가 입력되면, 메세지 히스토리로부터 메세지 목록을 가져온다.\n",
        "    input_messages_key=\"messages\",  # chain에 메세지 목록을 입력하기 위해 MessagePlaceholder의 메세지 키 값을 지정한다.\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc20\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "OglOz9_PHvj2",
        "outputId": "27c3a910-3289-410b-d555-e7cc497d6a4c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 0c5ff391-638d-4976-a9b3-4e7aa99e1325 not found for run 11d74135-f6a2-41af-bec9-12873bd95d0d. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't have access to personal information like your name. How can I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LG3wE97TIH2t",
        "outputId": "4a846470-0084-4816-ea2b-286c764f39ee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 8193790a-434b-4c14-a396-7184b1170bdb not found for run 46557c79-2f5f-4e5d-94ef-80835c2425b7. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You haven't asked a math problem yet. Feel free to ask any math question you have, and I'll be happy to help you solve it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming\n",
        "\n",
        "- 챗봇 애플리케이션에서 중요한 UX 고려사항은 스트링(streaming)이다.\n",
        "- LLM을 종종 응답값을 생성하는데 시간이 걸리기 때문에 대부분의 애플리케이션은 사용자 경험을 향상시키기 위해서 토큰이 생성될 때마다 각 토큰을 스트리밍한다."
      ],
      "metadata": {
        "id": "IoGgvt9JI5Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
        "\n",
        "for r in with_message_history.stream(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config\n",
        "):\n",
        "  print(r.content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd5feOa0I1h-",
        "outputId": "22c265e2-c439-49a5-ac1a-2ad98d222cb5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 60ecdee8-1218-4a99-9114-4d6c7aa4ed44 not found for run f6dc9f2c-cce3-40da-8317-0dedf2fd565a. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|Sure|,| Todd|!| Here|'s| a| joke| for| you|:\n",
            "\n",
            "|Why| don|'t| scientists| trust| atoms|?\n",
            "\n",
            "|Because| they| make| up| everything|!||"
          ]
        }
      ]
    }
  ]
}