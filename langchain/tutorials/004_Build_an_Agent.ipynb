{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build an Agent\n",
        "\n",
        "- 에이전트(agent)는 어떤 행동을하고 입력값을 결정하기 위해 LLM을 추론 엔진(reasoning engine)으로 사용한다.\n",
        "- 행동을 한 후에는 추가적인 행동이 필요한지 아니면 종료해도 되는지 결정하기 위해 결과를 LLM에게 입력한다."
      ],
      "metadata": {
        "id": "QhL5zn_CDX76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end agent\n",
        "\n",
        "- 아래 코드 스니펫은 LLM이 어느 도구를 사용할지 결정하는 완전한 함수형 에이전트를 보여준다."
      ],
      "metadata": {
        "id": "xCWtrN75CPBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant functionality\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Create the agent\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
        "model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
        "search = TavilySearchResults(max_results=2)\n",
        "tools = [search]\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "# Use the agent\n",
        "config {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
        "for chunk in agent_executor.stream(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]\n",
        "    },\n",
        "    config=config\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")\n",
        "\n",
        "for chunk in agent_executor.stream(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"whats the weather where i live?\")]\n",
        "    },\n",
        "    config=config\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ],
      "metadata": {
        "id": "8xmxUtqeBD5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2y3MceBdD5xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain-community langgraph langchain-anthropic tavily-python"
      ],
      "metadata": {
        "id": "I0QO4p7gCxhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "S8Q5OD-2Ec2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11f2d28-232f-4364-f72c-96120aaca163"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define tools\n",
        "\n",
        "- Tavily 검색 엔진을 도구로 쉽게 사용하기 위해 LangChain의 내장 도구를 사용한다."
      ],
      "metadata": {
        "id": "n28ONmK2DTkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=2)\n",
        "search_results = search.invoke(\"what is the weather in SF\")\n",
        "\n",
        "print(search_results)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later\n",
        "\n",
        "tools = [search]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_w629HRDMwN",
        "outputId": "bde94f6b-df7a-4aba-b7f7-c4a3e6c394a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94161/date/2024-6-21', 'content': 'Current Weather for Popular Cities . San Francisco, CA warning 56 ° F Fair; Manhattan, NY warning 73 ° F Sunny; Schiller Park, IL (60176) warning 78 ° F Partly Cloudy; Boston, MA warning 73 ...'}, {'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1718943994, 'localtime': '2024-06-20 21:26'}, 'current': {'last_updated_epoch': 1718943300, 'last_updated': '2024-06-20 21:15', 'temp_c': 13.3, 'temp_f': 55.9, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 280, 'wind_dir': 'W', 'pressure_mb': 1012.0, 'pressure_in': 29.88, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 84, 'cloud': 100, 'feelslike_c': 11.8, 'feelslike_f': 53.2, 'windchill_c': 10.1, 'windchill_f': 50.1, 'heatindex_c': 11.9, 'heatindex_f': 53.5, 'dewpoint_c': 9.9, 'dewpoint_f': 49.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 1.0, 'gust_mph': 15.4, 'gust_kph': 24.8}}\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Language Models"
      ],
      "metadata": {
        "id": "qmxwfDgKEMVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvcyCR45D7Pl",
        "outputId": "b981ac9c-b190-4bcc-8af1-a185db11badf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/327.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/327.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m317.4/327.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SBCrjMiERI0",
        "outputId": "52ebd71f-c2d5-4944-c7e7-c9dfc57c2d7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZmsEPKCREkC7",
        "outputId": "8cc2f486-e58d-47e3-aaf4-0b41143a5787"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 언어 모델의 검색 엔진 도구 호출을 활성하시키기 위해서 bind_tools 메소드를 사용한다."
      ],
      "metadata": {
        "id": "3nTYBPc9FBm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "GIOORBYIEwzE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 모델을 호출해보자. 먼저 일반 메세지로 모델을 호출하고 어떻게 응답이 오는지 확인한다."
      ],
      "metadata": {
        "id": "wO3boOwMFymS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe74rDZaFXAV",
        "outputId": "11dfa94a-aec5-4463-d950-2c86ae4c0e12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: Hello! How can I assist you today?\n",
            "ToolCalls: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이번에는 도구가 호출되도록 메세지를 수정한다."
      ],
      "metadata": {
        "id": "r7dvFyDPF-7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwzZbE3HFmG9",
        "outputId": "b1aa442b-b873-4408-dc8f-03546de31a8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_zIxTfipWYe9f8TPPgAddtlj5'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응답의 content 값이 존재하지 않지만 tool_calls 값은 존재한다."
      ],
      "metadata": {
        "id": "iRy69DPYGH4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the agent\n",
        "\n",
        "- 에이전트를 생성하기 위해 LangGraph를 사용할 것이다.\n",
        "- LLM과 도구를 가지고 에이전트를 초기화할 수 있다."
      ],
      "metadata": {
        "id": "ric5co7iGUaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "BIBCedyDFujs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the agent\n",
        "\n",
        "- 이제 몇 가지 쿼리로 에이전트를 실행할 수 있다."
      ],
      "metadata": {
        "id": "_EFFDFESG8K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
        "\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n1Draw1G7UF",
        "outputId": "68089487-f8a9-4331-9f1c-f1a8e95adee2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!', id='f4570329-a3aa-40e6-90d3-f242c583fe2d'),\n",
              " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b504ac44-f219-41dd-b016-faf7a3b04552-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93})]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        ")\n",
        "\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5yPPzfjHYSs",
        "outputId": "2b67dccb-54d2-4d91-db33-e62443926f98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='whats the weather in sf?', id='c0ce2b1f-8647-4015-9ee2-4e59b071b63d'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6zqaNuRl2fOfU8RHpCsKV3hD', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 88, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e35904d9-d2b7-406e-b64a-f5ebf8d96040-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_6zqaNuRl2fOfU8RHpCsKV3hD'}], usage_metadata={'input_tokens': 88, 'output_tokens': 21, 'total_tokens': 109}),\n",
              " ToolMessage(content='[{\"url\": \"https://world-weather.info/forecast/usa/san_francisco/june-2024/\", \"content\": \"Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed \\\\u26a1 San Francisco Weather Forecast for June 2024 - day/night \\\\ud83c\\\\udf21\\\\ufe0f temperatures, precipitations - World-Weather.info.\"}, {\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1718945141, \\'localtime\\': \\'2024-06-20 21:45\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718945100, \\'last_updated\\': \\'2024-06-20 21:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1012.0, \\'pressure_in\\': 29.88, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 84, \\'cloud\\': 100, \\'feelslike_c\\': 11.8, \\'feelslike_f\\': 53.2, \\'windchill_c\\': 10.1, \\'windchill_f\\': 50.1, \\'heatindex_c\\': 11.9, \\'heatindex_f\\': 53.5, \\'dewpoint_c\\': 9.9, \\'dewpoint_f\\': 49.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 15.4, \\'gust_kph\\': 24.8}}\"}]', name='tavily_search_results_json', id='a794c230-4c84-4e40-b66d-ab1a99464be1', tool_call_id='call_6zqaNuRl2fOfU8RHpCsKV3hD'),\n",
              " AIMessage(content='The current weather in San Francisco is overcast. The temperature is 13.3°C (55.9°F) with a wind speed of 15.1 kph coming from the west. The humidity is at 84%, and the visibility is 16.0 km.', response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 622, 'total_tokens': 680}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-12c0ffcf-9a87-4de6-a654-5c1eeda0d431-0', usage_metadata={'input_tokens': 622, 'output_tokens': 58, 'total_tokens': 680})]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming Messages"
      ],
      "metadata": {
        "id": "gybHBQ6tH9f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h9UbfjYHtFc",
        "outputId": "f6b02113-6817-406c-f4bd-adedb9a26816"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gRFOgcYAhkk8IGtqvJzct25A', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 88, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-248d640c-2ea4-4e3c-921a-7d88907f44bd-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_gRFOgcYAhkk8IGtqvJzct25A'}], usage_metadata={'input_tokens': 88, 'output_tokens': 21, 'total_tokens': 109})]}}\n",
            "----\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://world-weather.info/forecast/usa/san_francisco/june-2024/\", \"content\": \"Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed \\\\u26a1 San Francisco Weather Forecast for June 2024 - day/night \\\\ud83c\\\\udf21\\\\ufe0f temperatures, precipitations - World-Weather.info.\"}, {\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1718945141, \\'localtime\\': \\'2024-06-20 21:45\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718945100, \\'last_updated\\': \\'2024-06-20 21:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1012.0, \\'pressure_in\\': 29.88, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 84, \\'cloud\\': 100, \\'feelslike_c\\': 11.8, \\'feelslike_f\\': 53.2, \\'windchill_c\\': 10.1, \\'windchill_f\\': 50.1, \\'heatindex_c\\': 11.9, \\'heatindex_f\\': 53.5, \\'dewpoint_c\\': 9.9, \\'dewpoint_f\\': 49.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 15.4, \\'gust_kph\\': 24.8}}\"}]', name='tavily_search_results_json', tool_call_id='call_gRFOgcYAhkk8IGtqvJzct25A')]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 55.9°F (13.3°C)\\n- Condition: Overcast\\n- Wind: 15.1 km/h from the west\\n- Pressure: 29.88 in\\n- Humidity: 84%\\n- Cloud Cover: 100%\\n- Visibility: 9.0 miles\\n\\nFor more detailed information, you can visit [World Weather - San Francisco Forecast](https://world-weather.info/forecast/usa/san_francisco/june-2024/) or [Weather API - San Francisco](https://www.weatherapi.com/).', response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 622, 'total_tokens': 751}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5f5e794c-ceff-407b-808c-883666bb0822-0', usage_metadata={'input_tokens': 622, 'output_tokens': 129, 'total_tokens': 751})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming tokens"
      ],
      "metadata": {
        "id": "KvqlXqdjI5ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in agent_executor.astream_events(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chain_start\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print(\n",
        "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
        "            )\n",
        "    elif kind == \"on_chain_end\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print()\n",
        "            print(\"--\")\n",
        "            print(\n",
        "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
        "            )\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"|\")\n",
        "    elif kind == \"on_tool_start\":\n",
        "        print(\"--\")\n",
        "        print(\n",
        "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "        )\n",
        "    elif kind == \"on_tool_end\":\n",
        "        print(f\"Done tool: {event['name']}\")\n",
        "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "        print(\"--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnkY7y_YIJgc",
        "outputId": "e7172fec-f4c2-4b8b-c805-e27ecc19b15c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "Starting tool: tavily_search_results_json with inputs: {'query': 'weather in San Francisco'}\n",
            "Done tool: tavily_search_results_json\n",
            "Tool output was: [{'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94161/date/2024-6-21', 'content': 'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area.'}, {'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1718950020, 'localtime': '2024-06-20 23:07'}, 'current': {'last_updated_epoch': 1718949600, 'last_updated': '2024-06-20 23:00', 'temp_c': 13.3, 'temp_f': 55.9, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 2.2, 'wind_kph': 3.6, 'wind_degree': 10, 'wind_dir': 'N', 'pressure_mb': 1012.0, 'pressure_in': 29.88, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 84, 'cloud': 100, 'feelslike_c': 11.7, 'feelslike_f': 53.1, 'windchill_c': 9.8, 'windchill_f': 49.6, 'heatindex_c': 11.7, 'heatindex_f': 53.1, 'dewpoint_c': 9.8, 'dewpoint_f': 49.7, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 1.0, 'gust_mph': 15.5, 'gust_kph': 24.9}}\"}]\n",
            "--\n",
            "The| current| weather| in| San| Francisco| is| as| follows|:\n",
            "|-| Temperature|:| |55|.|9|°F| (|13|.|3|°C|)\n",
            "|-| Condition|:| Over|cast|\n",
            "|-| Wind|:| |3|.|6| km|/h|\n",
            "|-| Hum|idity|:| |84|%\n",
            "|-| Prec|ip|itation|:| |0|.|0| in|\n",
            "|-| Cloud| Cover|:| |100|%\n",
            "|-| Visibility|:| |9|.|0| miles|\n",
            "\n",
            "|For| more| detailed| information|,| you| can| visit| [|Weather| Underground|](|https|://|www|.w|under|ground|.com|/h|our|ly|/us|/ca|/s|an|-fr|anc|isco|/|941|61|/date|/|202|4|-|6|-|21|)| or| [|Weather| API|](|https|://|www|.weather|api|.com|/|).|"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding in memory\n",
        "\n",
        "- 앞서 언급한 대로, 에이전트는 무상태이다. 즉, 에이전트는 과거의 상호작요을 기억하지 못한다.\n",
        "- 에이전트에게 메모리 기능을 추가하기 위해서 체크 포인터를 전달해줄 필요가 있다.\n",
        "- 에이전트를 실행할 때 체크포인터와 함께 thread_id도 전달해줘야 한다."
      ],
      "metadata": {
        "id": "0KteEYIlawel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")"
      ],
      "metadata": {
        "id": "E4XG4-AOaH0M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "K-OeonIobYZ-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nduiIr0tbgyg",
        "outputId": "ea4f9de7-0a32-4a10-f1fa-e085721f7987"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 85, 'total_tokens': 96}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cce149da-de39-4b87-8bfd-565ee34c9862-0', usage_metadata={'input_tokens': 85, 'output_tokens': 11, 'total_tokens': 96})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO6cN72sbpXV",
        "outputId": "6fec8830-906d-45c1-9b3f-41aae1140048"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Your name is Bob! How can I help you, Bob?', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 108, 'total_tokens': 122}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6b9384f9-63ce-4c43-99c2-985f1923134a-0', usage_metadata={'input_tokens': 108, 'output_tokens': 14, 'total_tokens': 122})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 만약 새로운 대화를 시작하고 싶다면, thread_id만 변경해주면 된다."
      ],
      "metadata": {
        "id": "nZCjOPNNb2bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jgs6UfPbyvF",
        "outputId": "fdd40bbb-d9af-46a8-e4f3-215b915d4963"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"I don't have access to personal information like your name. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 86, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-333c4831-440d-4ae5-912c-336b8a5d8777-0', usage_metadata={'input_tokens': 86, 'output_tokens': 20, 'total_tokens': 106})]}}\n",
            "----\n"
          ]
        }
      ]
    }
  ]
}